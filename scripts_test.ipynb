{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "pio.templates.default = \"plotly_dark\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from src.product import Product\n",
    "from json import load\n",
    "\n",
    "with open('agora_hack_products.json', encoding='utf-8') as file:\n",
    "    all_products = load(file)\n",
    "\n",
    "all_products = [Product(**p) for p in all_products]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "references = [p for p in all_products if p.is_reference]\n",
    "references_id_set = set([ref.product_id for ref in references])\n",
    "products = [p for p in all_products if p.product_id not in references_id_set]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# удалим часть эталонов, что бы в датасете были 'ничейные' товары\n",
    "references, nulled_references = train_test_split(\n",
    "    references, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "nulled_references_set = set([r.product_id for r in nulled_references])\n",
    "for p in products:\n",
    "    if p.reference_id in nulled_references_set:\n",
    "        p.reference_id = None\n",
    "for p in nulled_references:\n",
    "    p.is_reference = False\n",
    "    p.reference_id = None\n",
    "\n",
    "products.extend(nulled_references)\n",
    "\n",
    "products_train, products_test = train_test_split(\n",
    "    products, test_size=0.5, random_state=42\n",
    ")\n",
    "products_train.extend(references)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from json import dump\n",
    "\n",
    "def product2dict(p):\n",
    "    return p.__dict__\n",
    "\n",
    "def product2req(p):\n",
    "    return {\n",
    "        'id': p.product_id,\n",
    "        'name': p.name,\n",
    "        'props': p.props,\n",
    "    }\n",
    "\n",
    "def product2ans(p):\n",
    "    return {\n",
    "        'id': p.product_id,\n",
    "        'reference_id': p.reference_id,\n",
    "    }\n",
    "\n",
    "with open('server_test_train.json', 'w', encoding='utf-8') as f:\n",
    "    dump(list(map(product2dict, products_train)), f, ensure_ascii=False)\n",
    "with open('server_test_target.json', 'w', encoding='utf-8') as f:\n",
    "    dump(list(map(product2dict, products_test)), f, ensure_ascii=False)\n",
    "\n",
    "\n",
    "#with open('server_test_test.json', 'w') as f:\n",
    "#    dump(list(map(product2req, products_test)), f)\n",
    "#with open('server_test_ans.json', 'w') as f:\n",
    "#    dump(list(map(product2ans, products_test)), f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def accuracy(predicted, target):\n",
    "    return list(map(lambda v: v[0] == v[1], zip(predicted, target))).count(True) / len(predicted)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "import copy\n",
    "\n",
    "def augment_train(prods: [Product], count=2):\n",
    "    res = []\n",
    "    for p in prods:\n",
    "        for _ in range(count):\n",
    "            p_ = copy.deepcopy(p)\n",
    "            p_.props = random.sample(p_.props, random.randint(len(p_.props) // 2, len(p_.props)))\n",
    "            name_parts = p_.name.split()\n",
    "            p_.name = ' '.join(random.sample(name_parts, random.randint(len(name_parts) // 2, len(name_parts))))\n",
    "\n",
    "            res.append(p_)\n",
    "\n",
    "    prods.extend(res)\n",
    "    random.shuffle(prods)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "#augment_train(all_products)\n",
    "#len(all_products)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "hand_test = []\n",
    "for i in range(3):\n",
    "    with open(f'test_data/data_{i}.json', encoding='utf-8') as f:\n",
    "        hand_test.extend(load(f))\n",
    "\n",
    "hand_test = [Product(**p) for p in hand_test]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8156424581005587 0.8199863107460643 0.3969465648854962\n"
     ]
    }
   ],
   "source": [
    "from src.model import ProductMatchingModel\n",
    "from sklearn.svm import OneClassSVM, LinearSVC, SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from spacy.lang.en import STOP_WORDS as EN_STOP_WORDS\n",
    "from spacy.lang.ru import STOP_WORDS as RU_STOP_WORDS\n",
    "\n",
    "model = ProductMatchingModel(RidgeClassifier(alpha=0.4),\n",
    "                             RidgeClassifier(alpha=0.1),\n",
    "                             RidgeClassifier(alpha=0.1),\n",
    "                             CountVectorizer(stop_words=RU_STOP_WORDS or EN_STOP_WORDS))\n",
    "\n",
    "model.fit(products_train)\n",
    "\n",
    "\n",
    "print(\n",
    "    accuracy(model.predict(products_train), map(lambda p: p.reference_id, products_train)),\\\n",
    "    accuracy(model.predict(products_test), map(lambda p: p.reference_id, products_test)),\\\n",
    "    accuracy(model.predict(hand_test), map(lambda p: p.reference_id, hand_test))\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "model.dump('model.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8039835acce4071a1f801d231791cbd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'brut_ml' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m df \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m th \u001B[38;5;129;01min\u001B[39;00m tqdm(np\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m60\u001B[39m, \u001B[38;5;241m3\u001B[39m)):\n\u001B[1;32m----> 3\u001B[0m     df\u001B[38;5;241m.\u001B[39mappend([th, \u001B[38;5;241m*\u001B[39m\u001B[43mbrut_ml\u001B[49m(th)])\n\u001B[0;32m      5\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(df, columns\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mthreshold\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "\u001B[1;31mNameError\u001B[0m: name 'brut_ml' is not defined"
     ]
    }
   ],
   "source": [
    "df = []\n",
    "for th in tqdm(np.arange(5, 60, 3)):\n",
    "    df.append([th, *brut_ml(th)])\n",
    "\n",
    "df = pd.DataFrame(df, columns=['threshold', 'train', 'test', 'val'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "px.line(df, x='threshold', y=['train', 'test', 'val'], )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def classify_error(pred, targ):\n",
    "    if pred == targ:\n",
    "        return\n",
    "    if pred is None and targ is not None:\n",
    "        return 'freerider'\n",
    "    if pred is not None and targ is None:\n",
    "        return 'bastard'\n",
    "    return 'chameleon'\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "results = list(zip(model.predict(hand_test), map(lambda p: p.reference_id, hand_test)))\n",
    "cnt = Counter([classify_error(a, b) for a, b in results if a != b])\n",
    "print('acc=', 1 - sum(cnt.values()) / len(results))\n",
    "cnt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for r, product_given in zip(results, hand_test):\n",
    "        predicted, target = r\n",
    "    #if predicted != target:\n",
    "        print('\\n\\n<=====================>\\n')\n",
    "\n",
    "        print(product_given)\n",
    "\n",
    "        print('\\n matched with \\n')\n",
    "\n",
    "        print(*filter(lambda p: p.product_id == predicted, references))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "0/0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import RidgeClassifier, SGDClassifier\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from spacy.lang.en import STOP_WORDS as EN_STOP_WORDS\n",
    "from spacy.lang.ru import STOP_WORDS as RU_STOP_WORDS\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from model import ProductMatchingModel\n",
    "\n",
    "use_models = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "]\n",
    "\n",
    "models = list(zip(map(lambda m: m.__class__.__name__, use_models), use_models)) # now its [(name, model), ...]\n",
    "\n",
    "model_tests_df = []\n",
    "for name, model in models:\n",
    "    master_model = ProductMatchingModel(RidgeClassifier(alpha=1.9), clone(model), clone(model),\n",
    "                                        vectorizer=TfidfVectorizer(stop_words=RU_STOP_WORDS or EN_STOP_WORDS))\n",
    "    master_model.fit(all_products)\n",
    "    train_acc, test_acc, hand_acc = accuracy(master_model.predict(all_products), map(lambda p: p.reference_id, all_products)),\\\n",
    "                          accuracy(master_model.predict(products_test), map(lambda p: p.reference_id, products_test)),\\\n",
    "                          accuracy(master_model.predict(hand_test), map(lambda p: p.reference_id, hand_test)),\n",
    "\n",
    "    print(name, f\"train: {train_acc}, test: {test_acc}, hand: {hand_acc}\")\n",
    "    model_tests_df.append([name, train_acc, test_acc, hand_acc])\n",
    "\n",
    "model_tests_df = pd.DataFrame(model_tests_df, columns=['name', 'train_acc', 'test_acc', 'hand_acc'])\n",
    "\n",
    "bar = px.bar(model_tests_df, x='name', y=['train_acc', 'test_acc', 'hand_acc'], barmode='group', log_y=False)\n",
    "bar.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}