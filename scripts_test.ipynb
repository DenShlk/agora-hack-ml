{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from product import Product\n",
    "from json import load\n",
    "\n",
    "with open('agora_hack_products.json', encoding='utf-8') as file:\n",
    "    all_products = load(file)\n",
    "\n",
    "all_products = [Product(**p) for p in all_products]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "references = [p for p in all_products if p.is_reference]\n",
    "references_id_set = set([ref.product_id for ref in references])\n",
    "products = [p for p in all_products if p.product_id not in references_id_set]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# удалим часть эталонов, что бы в датасете были 'ничейные' товары\n",
    "references, nulled_references = train_test_split(\n",
    "    references, test_size=0.5 , random_state=42\n",
    ")\n",
    "references += nulled_references\n",
    "nulled_references = []\n",
    "\n",
    "nulled_references_set = set([r.product_id for r in nulled_references])\n",
    "for p in products:\n",
    "    if p.reference_id in nulled_references_set:\n",
    "        p.reference_id = None\n",
    "\n",
    "products_train, products_test = train_test_split(\n",
    "    products, test_size=0.5, random_state=42\n",
    ")\n",
    "all_products = products_train + references\n",
    "products_test = products_test + nulled_references"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def accuracy(predicted, target):\n",
    "    return list(map(lambda v: v[0] == v[1], zip(predicted, target))).count(True) / len(predicted)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "hand_test = []\n",
    "for i in range(4,5):\n",
    "    with open(f'test_data/data_{i}.json', encoding='utf-8') as f:\n",
    "        hand_test.extend(load(f))\n",
    "\n",
    "hand_test = [Product(**p) for p in hand_test]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7463729177861365 0.9474820143884892 0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import OneClassSVM, LinearSVC, SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from spacy.lang.en import STOP_WORDS as EN_STOP_WORDS\n",
    "from spacy.lang.ru import STOP_WORDS as RU_STOP_WORDS\n",
    "\n",
    "\n",
    "from model import ProductMatchingModel\n",
    "\n",
    "\n",
    "model = ProductMatchingModel(RidgeClassifier(alpha=0.4),\n",
    "                             RidgeClassifier(alpha=0.1),\n",
    "                             RidgeClassifier(alpha=0.1),\n",
    "                             TfidfVectorizer(stop_words=RU_STOP_WORDS or EN_STOP_WORDS))\n",
    "\n",
    "model.fit(all_products)\n",
    "\n",
    "print(accuracy(model.predict(all_products), map(lambda p: p.reference_id, all_products)),\n",
    "accuracy(model.predict(products_test), map(lambda p: p.reference_id, products_test)),\n",
    "accuracy(model.predict(hand_test), map(lambda p: p.reference_id, hand_test)),)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = ProductMatchingModel(RidgeClassifier(alpha=0.4),\n",
    "                             RidgeClassifier(alpha=0.1),\n",
    "                             RidgeClassifier(alpha=0.1),\n",
    "                             TfidfVectorizer(stop_words=RU_STOP_WORDS or EN_STOP_WORDS))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def classify_error(pred, targ):\n",
    "    if pred == targ:\n",
    "        return\n",
    "    if pred is None and targ is not None:\n",
    "        return 'freerider'\n",
    "    if pred is not None and targ is None:\n",
    "        return 'bastard'\n",
    "    return 'chameleon'\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [13]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcollections\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Counter\n\u001B[1;32m----> 4\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhand_test\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mmap\u001B[39m(\u001B[38;5;28;01mlambda\u001B[39;00m p: p\u001B[38;5;241m.\u001B[39mreference_id, hand_test)))\n\u001B[0;32m      5\u001B[0m cnt \u001B[38;5;241m=\u001B[39m Counter([classify_error(a, b) \u001B[38;5;28;01mfor\u001B[39;00m a,b \u001B[38;5;129;01min\u001B[39;00m results \u001B[38;5;28;01mif\u001B[39;00m a \u001B[38;5;241m!=\u001B[39m b])\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124macc=\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m \u001B[38;5;28msum\u001B[39m(cnt\u001B[38;5;241m.\u001B[39mvalues()) \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(results))\n",
      "File \u001B[1;32m~\\DataspellProjects\\hack\\agora\\model.py:83\u001B[0m, in \u001B[0;36mProductMatchingModel.predict\u001B[1;34m(self, products)\u001B[0m\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, products: [Product]):\n\u001B[0;32m     82\u001B[0m     products \u001B[38;5;241m=\u001B[39m deepcopy(products)\n\u001B[1;32m---> 83\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclass2id \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     85\u001B[0m     corpus \u001B[38;5;241m=\u001B[39m preprocess\u001B[38;5;241m.\u001B[39mproducts2corpus(products)\n\u001B[0;32m     86\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvectorizer\u001B[38;5;241m.\u001B[39mtransform(corpus)\u001B[38;5;241m.\u001B[39mtoarray()\n",
      "\u001B[1;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "results = list(zip(model.predict(hand_test), map(lambda p: p.reference_id, hand_test)))\n",
    "cnt = Counter([classify_error(a, b) for a,b in results if a != b])\n",
    "print('acc=', 1 - sum(cnt.values()) / len(results))\n",
    "cnt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for r, product_given in zip(results, hand_test):\n",
    "        predicted, target = r\n",
    "    #if predicted != target:\n",
    "        print('\\n\\n<=====================>\\n')\n",
    "\n",
    "        print(product_given)\n",
    "\n",
    "        print('\\n matched with \\n')\n",
    "\n",
    "        print(*filter(lambda p: p.product_id == predicted, references))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "0/0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, RadiusNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import RidgeClassifier, SGDClassifier\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from spacy.lang.en import STOP_WORDS as EN_STOP_WORDS\n",
    "from spacy.lang.ru import STOP_WORDS as RU_STOP_WORDS\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from model import ProductMatchingModel\n",
    "\n",
    "use_models = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "]\n",
    "\n",
    "models = list(zip(map(lambda m: m.__class__.__name__, use_models), use_models)) # now its [(name, model), ...]\n",
    "\n",
    "model_tests_df = []\n",
    "for name, model in models:\n",
    "    master_model = ProductMatchingModel(RidgeClassifier(alpha=1.9), clone(model), clone(model),\n",
    "                                        vectorizer=TfidfVectorizer(stop_words=RU_STOP_WORDS or EN_STOP_WORDS))\n",
    "    master_model.fit(all_products)\n",
    "    train_acc, test_acc, hand_acc = accuracy(master_model.predict(all_products), map(lambda p: p.reference_id, all_products)),\\\n",
    "                          accuracy(master_model.predict(products_test), map(lambda p: p.reference_id, products_test)),\\\n",
    "                          accuracy(master_model.predict(hand_test), map(lambda p: p.reference_id, hand_test)),\n",
    "\n",
    "    print(name, f\"train: {train_acc}, test: {test_acc}, hand: {hand_acc}\")\n",
    "    model_tests_df.append([name, train_acc, test_acc, hand_acc])\n",
    "\n",
    "model_tests_df = pd.DataFrame(model_tests_df, columns=['name', 'train_acc', 'test_acc', 'hand_acc'])\n",
    "\n",
    "bar = px.bar(model_tests_df, x='name', y=['train_acc', 'test_acc', 'hand_acc'], barmode='group', log_y=False)\n",
    "bar.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}